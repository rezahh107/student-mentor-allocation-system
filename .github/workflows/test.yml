name: Windows Tests Enhanced

on:
  push:
    branches: ["main", "master", "develop"]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read
  checks: write
  pull-requests: write

concurrency:
  group: windows-tests-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHONUTF8: "1"
  FAKE_WEBVIEW: "1"
  PYTHONWARNINGS: "error"
  PYTEST_DISABLE_PLUGIN_AUTOLOAD: "1"
  PYTHONHASHSEED: "0"
  TZ: "Asia/Tehran"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_PROGRESS_BAR: "off"

defaults:
  run:
    shell: pwsh
    working-directory: ${{ github.workspace }}

jobs:
  test:
    name: Windows CI (Python ${{ matrix.python-version }})
    runs-on: windows-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11.9', '3.12']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: |
            constraints-dev.txt
            requirements-dev.in
            requirements.txt
            requirements-test.txt
            pyproject.toml

      - name: Display environment
        run: |
          Write-Host "Python:" (python --version)
          Write-Host "Location:" (Get-Location)
          Get-ChildItem -Force

      - name: Install dependencies (constraints-aware, retry)
        run: |
          $ErrorActionPreference = 'Stop'
          function Invoke-WithRetry {
            param([scriptblock]$Script,[int]$MaxAttempts=4)
            for ($i=1; $i -le $MaxAttempts; $i++) {
              try { & $Script; return } catch {
                if ($i -eq $MaxAttempts) { throw }
                $delay = [Math]::Min(8, [Math]::Pow(2,$i)) + (Get-Random -Min 0 -Max 2)
                Write-Warning "Attempt $i failed: $($_.Exception.Message). Retrying in $delay s..."
                Start-Sleep -Seconds $delay
              }
            }
          }
          Invoke-WithRetry { python -m pip install --upgrade pip wheel setuptools }
          if (Test-Path "constraints-dev.txt" -and Test-Path "requirements-dev.in") {
            Invoke-WithRetry { pip install -c constraints-dev.txt -r requirements-dev.in }
          } else {
            Invoke-WithRetry { pip install -r requirements-test.txt }
          }
          Invoke-WithRetry { pip install -e . }

      - name: Run full pytest suite with coverage (deterministic)
        env:
          PYTEST_CURRENT_TEST: ci-windows
        run: |
          $ErrorActionPreference = 'Stop'
          New-Item -ItemType Directory -Force -Path test-results | Out-Null
          python -m pytest `
            --tb=short --strict-config --strict-markers --maxfail=1 `
            --rootdir "$PWD" `
            --ignore-glob="**/System Volume Information" `
            --ignore-glob="**/WindowsApps" `
            --ignore-glob="**/Program Files" `
            --ignore-glob="**/Program Files (x86)" `
            --cov=src `
            --cov-report=xml `
            --cov-report=html:test-results/htmlcov `
            --cov-report=term `
            --json-report `
            --json-report-file=test-results/pytest-report.json `
            --junitxml=test-results/junit.xml `
            --html=test-results/report.html `
            --self-contained-html

      - name: Publish unit test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: test-results/junit.xml

      - name: Upload coverage xml
        if: always() && matrix.python-version == '3.11.9'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml
          if-no-files-found: error

      - name: Upload HTML coverage
        if: always() && matrix.python-version == '3.11.9'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html
          path: test-results/htmlcov
          if-no-files-found: warn

      - name: Upload pytest reports
        if: always() && matrix.python-version == '3.11.9'
        uses: actions/upload-artifact@v4
        with:
          name: pytest-reports
          path: |
            test-results/pytest-report.json
            test-results/junit.xml
            test-results/report.html
          if-no-files-found: warn

      - name: Upload raw pytest cache on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-cache-${{ matrix.python-version }}
          path: .pytest_cache
          if-no-files-found: ignore

  performance:
    name: Windows Performance Benchmarks (Python 3.11.9)
    runs-on: windows-latest
    timeout-minutes: 45
    needs: test

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11.9'
          cache: 'pip'
          cache-dependency-path: |
            constraints-dev.txt
            requirements-dev.in
            requirements.txt
            requirements-test.txt
            pyproject.toml

      - name: Install dependencies (constraints-aware)
        run: |
          $ErrorActionPreference = 'Stop'
          python -m pip install --upgrade pip
          if (Test-Path "constraints-dev.txt" -and Test-Path "requirements-dev.in") {
            pip install -c constraints-dev.txt -r requirements-dev.in
          } else {
            pip install -r requirements-test.txt
          }
          pip install -e .

      - name: Prepare artifacts directory
        run: |
          New-Item -ItemType Directory -Force -Path artifacts | Out-Null
          Remove-Item -Recurse -Force .benchmarks -ErrorAction SilentlyContinue

      - name: Run performance benchmarks
        run: |
          $ErrorActionPreference = 'Stop'
          python -m pytest tests/performance `
            --rootdir "$PWD" `
            --ignore-glob="**/System Volume Information" `
            --ignore-glob="**/WindowsApps" `
            --ignore-glob="**/Program Files" `
            --ignore-glob="**/Program Files (x86)" `
            -p pytest_benchmark.plugin `
            -n=0 `
            --dist=no `
            --benchmark-only `
            --benchmark-json=artifacts/pytest-benchmark.json `
            --benchmark-compare `
            --benchmark-min-rounds=5 `
            --maxfail=1

      - name: Download coverage xml
        uses: actions/download-artifact@v4
        with:
          name: coverage-xml
          path: artifacts/coverage

      - name: Download pytest reports
        uses: actions/download-artifact@v4
        with:
          name: pytest-reports
          path: artifacts/test-results

      - name: Generate consolidated test report
        run: |
          python scripts/generate_test_report.py `
            --coverage artifacts/coverage/coverage.xml `
            --pytest-json artifacts/test-results/pytest-report.json `
            --bench-json artifacts/pytest-benchmark.json `
            --perf-json artifacts/performance-metrics.json `
            --output reports/test-report.md `
            --badge reports/coverage_badge.svg

      - name: Upload performance artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-artifacts
          path: |
            artifacts/pytest-benchmark.json
            artifacts/performance-metrics.json
            reports/test-report.md
            reports/coverage_badge.svg
          if-no-files-found: warn

      - name: Upload benchmark cache
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-benchmark-cache
          path: .benchmarks
          if-no-files-found: warn
