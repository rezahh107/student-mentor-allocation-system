name: Windows Tests Enhanced

on:
  push:
    branches: ["main", "master", "develop"]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read
  checks: write
  pull-requests: write

concurrency:
  group: windows-tests-${{ github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

env:
  PYTHONUTF8: "1"
  FAKE_WEBVIEW: "1"
  PYTHONWARNINGS: "error"
  PYTEST_DISABLE_PLUGIN_AUTOLOAD: "1"
  PYTHONHASHSEED: "0"
  TZ: "Asia/Tehran"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_PROGRESS_BAR: "off"
  # Windows-specific optimizations
  TEMP: "D:\\temp"
  TMP: "D:\\temp"
  PIP_CACHE_DIR: "D:\\pip-cache"
  PYTEST_TMPDIR: "D:\\pytest-tmp"

defaults:
  run:
    shell: pwsh
    working-directory: ${{ github.workspace }}

jobs:
  test:
    name: Windows CI (Python ${{ matrix.python-version }})
    runs-on: windows-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11.9', '3.12']

    steps:
      - name: Initialize Windows environment
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Create isolated directories with proper permissions
          $dirs = @('D:\temp', 'D:\pip-cache', 'D:\pytest-tmp', 'D:\test-workspace')
          foreach ($dir in $dirs) {
            New-Item -ItemType Directory -Force -Path $dir | Out-Null
            $acl = Get-Acl $dir
            $permission = [System.Security.AccessControl.FileSystemAccessRule]::new(
              "Everyone", "FullControl", "ContainerInherit,ObjectInherit", "None", "Allow"
            )
            $acl.SetAccessRule($permission)
            Set-Acl -Path $dir -AclObject $acl
          }
          
          # Set Windows Defender exclusions for performance
          Add-MpPreference -ExclusionPath $dirs -ErrorAction SilentlyContinue

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          path: 'D:\test-workspace'

      - name: Setup Python with enhanced caching
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          architecture: 'x64'
          cache: 'pip'
          cache-dependency-path: |
            D:\test-workspace\constraints-dev.txt
            D:\test-workspace\requirements*.txt
            D:\test-workspace\pyproject.toml

      - name: Install dependencies with resilient retry
        working-directory: D:\test-workspace
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Enhanced retry function with exponential backoff
          function Invoke-ResilientCommand {
            param(
              [scriptblock]$Command,
              [int]$MaxAttempts = 5,
              [string]$Description = "command"
            )
            
            $attempt = 0
            $baseDelay = 2
            
            while ($attempt -lt $MaxAttempts) {
              $attempt++
              try {
                Write-Host "[$attempt/$MaxAttempts] Executing: $Description"
                $result = & $Command
                Write-Host "âœ“ Success: $Description"
                return $result
              }
              catch {
                $delay = [Math]::Min(60, $baseDelay * [Math]::Pow(2, $attempt - 1))
                $jitter = Get-Random -Minimum 0 -Maximum 3
                $totalDelay = $delay + $jitter
                
                if ($attempt -eq $MaxAttempts) {
                  Write-Error "Failed after $MaxAttempts attempts: $_"
                  throw
                }
                
                Write-Warning "Attempt $attempt failed: $_"
                Write-Host "Retrying in $totalDelay seconds..."
                Start-Sleep -Seconds $totalDelay
              }
            }
          }
          
          # Upgrade pip with retry
          Invoke-ResilientCommand -Description "pip upgrade" -Command {
            python -m pip install --upgrade --no-warn-script-location pip wheel setuptools
          }
          
          # Dependency resolution with fallback strategy
          $installed = $false
          
          # Strategy 1: Constraints-based installation
          if ((Test-Path 'constraints-dev.txt') -and (Test-Path 'requirements-dev.in')) {
            try {
              Invoke-ResilientCommand -Description "constraints install" -Command {
                python -m pip install --no-deps -c constraints-dev.txt -r requirements-dev.in
                python -m pip install --no-deps -c constraints-dev.txt .
              }
              $installed = $true
            }
            catch {
              Write-Warning "Constraints installation failed, trying fallback..."
            }
          }
          
          # Strategy 2: Direct requirements installation
          if (-not $installed) {
            $reqFiles = @('requirements-test.txt', 'requirements-dev.txt', 'requirements.txt')
            foreach ($reqFile in $reqFiles) {
              if (Test-Path $reqFile) {
                Invoke-ResilientCommand -Description "$reqFile install" -Command {
                  python -m pip install -r $reqFile
                }
                $installed = $true
                break
              }
            }
          }
          
          # Install project in editable mode
          Invoke-ResilientCommand -Description "project install" -Command {
            python -m pip install -e . --no-build-isolation
          }
          
          # Verify installation integrity
          python -m pip check
          python -c "import sys; print(f'Python {sys.version}')"

      - name: Run deterministic test suite
        working-directory: D:\test-workspace
        env:
          PYTEST_CURRENT_TEST: "ci-windows-${{ matrix.python-version }}"
          COVERAGE_CORE: "sysmon"
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Create results directory
          $resultsDir = "D:\test-workspace\test-results"
          New-Item -ItemType Directory -Force -Path $resultsDir | Out-Null
          
          # Configure pytest with Windows-safe paths
          $pytestArgs = @(
            '--tb=short',
            '--strict-config',
            '--strict-markers',
            '--maxfail=3',
            '--timeout=300',
            '--timeout-method=thread',
            "--rootdir=D:\test-workspace",
            "--basetemp=D:\pytest-tmp",
            '--ignore-glob=**\System Volume Information',
            '--ignore-glob=**\WindowsApps',
            '--ignore-glob=**\Program Files*',
            '--ignore-glob=**\Windows',
            '--ignore-glob=**\Users\*\AppData',
            '--cov=src',
            '--cov-report=xml:coverage.xml',
            "--cov-report=html:$resultsDir\htmlcov",
            '--cov-report=term-missing:skip-covered',
            '--json-report',
            "--json-report-file=$resultsDir\pytest-report.json",
            "--junitxml=$resultsDir\junit.xml",
            "--html=$resultsDir\report.html",
            '--self-contained-html',
            '-v'
          )
          
          # Run tests with automatic retry on transient failures
          $maxTestAttempts = 2
          $testAttempt = 0
          $testSuccess = $false
          
          while (($testAttempt -lt $maxTestAttempts) -and (-not $testSuccess)) {
            $testAttempt++
            try {
              Write-Host "Test attempt $testAttempt of $maxTestAttempts"
              python -m pytest $pytestArgs
              $testSuccess = $true
            }
            catch {
              if ($testAttempt -eq $maxTestAttempts) {
                Write-Error "Tests failed after $maxTestAttempts attempts"
                throw
              }
              Write-Warning "Test attempt $testAttempt failed, retrying..."
              Start-Sleep -Seconds 5
            }
          }

      - name: Publish test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action/windows@v2
        with:
          files: 'D:\test-workspace\test-results\junit.xml'
          check_name: 'Test Results (Python ${{ matrix.python-version }})'
          comment_mode: 'off'

      - name: Upload coverage artifacts
        if: always() && matrix.python-version == '3.11.9'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-py311
          path: |
            D:\test-workspace\coverage.xml
            D:\test-workspace\test-results\htmlcov
          retention-days: 7

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-py${{ matrix.python-version }}
          path: D:\test-workspace\test-results
          retention-days: 7

      - name: Cleanup workspace
        if: always()
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'SilentlyContinue'
          
          # Remove temporary directories
          Remove-Item -Recurse -Force 'D:\pytest-tmp' -ErrorAction SilentlyContinue
          Remove-Item -Recurse -Force 'D:\temp\*' -ErrorAction SilentlyContinue
          
          # Clear pip cache if needed
          if ((Get-ChildItem 'D:\pip-cache' -Recurse | Measure-Object -Property Length -Sum).Sum -gt 1GB) {
            Remove-Item -Recurse -Force 'D:\pip-cache\*'
          }

  performance:
    name: Performance Benchmarks
    runs-on: windows-latest
    timeout-minutes: 30
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Initialize benchmark environment
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Create benchmark workspace
          New-Item -ItemType Directory -Force -Path 'D:\bench-workspace' | Out-Null
          New-Item -ItemType Directory -Force -Path 'D:\bench-artifacts' | Out-Null

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          path: 'D:\bench-workspace'

      - name: Setup Python for benchmarks
        uses: actions/setup-python@v5
        with:
          python-version: '3.11.9'
          architecture: 'x64'
          cache: 'pip'

      - name: Install benchmark dependencies
        working-directory: D:\bench-workspace
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          python -m pip install --upgrade pip wheel
          python -m pip install pytest-benchmark pytest-json-report
          
          if (Test-Path 'requirements-bench.txt') {
            python -m pip install -r requirements-bench.txt
          }
          elseif (Test-Path 'requirements-test.txt') {
            python -m pip install -r requirements-test.txt
          }
          
          python -m pip install -e . --no-build-isolation

      - name: Run performance benchmarks
        working-directory: D:\bench-workspace
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Run benchmarks with consistent configuration
          python -m pytest tests/performance `
            --benchmark-only `
            --benchmark-json='D:\bench-artifacts\benchmark.json' `
            --benchmark-autosave `
            --benchmark-max-time=2 `
            --benchmark-min-rounds=5 `
            --benchmark-warmup=on `
            --benchmark-disable-gc `
            --benchmark-sort=fullname `
            -v

      - name: Analyze benchmark results
        working-directory: D:\bench-workspace
        run: |
          Set-StrictMode -Version Latest
          $ErrorActionPreference = 'Stop'
          
          # Generate performance report
          if (Test-Path 'scripts/analyze_benchmarks.py') {
            python scripts/analyze_benchmarks.py `
              --input 'D:\bench-artifacts\benchmark.json' `
              --output 'D:\bench-artifacts\performance-report.md'
          }

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: D:\bench-artifacts
          retention-days: 30
