"""Deterministic PII scanner for CI pipelines.

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ØªØ±Ù…ÛŒÙ†ÛŒØ³ØªÛŒÚ© Ú©Ù„ Ù…Ø®Ø²Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³
Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª HMAC Ù…Ø§Ø³Ú© Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ JSON
Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯. Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡Ù” Ø­Ø³Ø§Ø³ØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ø§ Ú©Ø¯ Û±
Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯ ØªØ§ Ø®Ø·ÙˆØ· CI Ù…ØªÙˆÙ‚Ù Ø´ÙˆÙ†Ø¯.
"""

from __future__ import annotations

import argparse
import hashlib
import hmac
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Iterator, List, Optional, Sequence, Tuple

import re

from sma.phase6_import_to_sabt.sanitization import sanitize_phone, sanitize_text


class ScanError(RuntimeError):
    """Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³Ú©Ù†."""


@dataclass(frozen=True)
class Finding:
    """ÛŒØ§ÙØªÙ‡Ù” Ø¯Ø§Ø¯Ù‡Ù” Ø­Ø³Ø§Ø³."""

    file: Path
    line: int
    kind: str
    masked: str


@dataclass(frozen=True)
class _Pattern:
    name: str
    regex: "re.Pattern[str]"
    variant: str


SCAN_EXTENSIONS = {
    ".py",
    ".log",
    ".txt",
    ".json",
    ".yaml",
    ".yml",
    ".md",
    ".csv",
}

EXCLUDE_DIRS = {
    ".git",
    "__pycache__",
    "tmp",
    "tmpfile",
    "node_modules",
    ".mypy_cache",
    ".pytest_cache",
    "reports",  # Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
}


PATTERNS: Tuple[_Pattern, ...] = (
    _Pattern("national_id", re.compile(r"\b\d{10}\b"), "sanitized"),
    _Pattern("mobile", re.compile(r"09\d{9}"), "phone"),
)


def coerce_to_text(value: Optional[object]) -> str:
    """Ensure any input is converted to a safe string for scanning."""

    if value is None:
        return ""
    if isinstance(value, bytes):
        return value.decode("utf-8", "ignore")
    return str(value)


def compute_repo_root(start: Optional[Path] = None) -> Path:
    root = (start or Path(__file__)).resolve()
    for candidate in (root,) + tuple(root.parents):
        if (candidate / "reports").exists() and (candidate / "scripts").exists():
            return candidate
    raise ScanError("Ø±ÛŒØ´Ù‡Ù” Ù…Ø®Ø²Ù† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯Ø› Ø³Ø§Ø®ØªØ§Ø± reports/ Ùˆ scripts/ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª.")


def compute_repo_salt(repo_root: Path) -> bytes:
    digest = hashlib.sha256(str(repo_root).encode("utf-8")).digest()
    return digest


def mask_secret(value: str, repo_root: Path) -> str:
    normalized = sanitize_text(value)
    secret = normalized.encode("utf-8")
    salt = compute_repo_salt(repo_root)
    digest = hmac.new(salt, secret, hashlib.sha256).hexdigest()
    return digest[:32]


def normalize_variants(text: str) -> dict[str, str]:
    sanitized = sanitize_text(text)
    return {
        "raw": text,
        "sanitized": sanitized,
        "phone": sanitize_phone(text),
    }


def iter_sensitive_tokens(text: str) -> Iterator[Tuple[str, str]]:
    variants = normalize_variants(coerce_to_text(text))
    for pattern in PATTERNS:
        haystack = variants[pattern.variant]
        for match in pattern.regex.finditer(haystack):
            yield (pattern.name, match.group(0))


def iter_candidate_files(repo_root: Path) -> Iterator[Path]:
    for path in repo_root.rglob("*"):
        if not path.is_file():
            continue
        if any(part in EXCLUDE_DIRS for part in path.parts):
            continue
        if path.suffix.lower() not in SCAN_EXTENSIONS:
            continue
        yield path


def scan_file(path: Path, repo_root: Path) -> List[Finding]:
    findings: List[Finding] = []
    try:
        with path.open("r", encoding="utf-8", errors="ignore") as handle:
            for idx, line in enumerate(handle, 1):
                for kind, value in iter_sensitive_tokens(line):
                    findings.append(
                        Finding(
                            file=path.relative_to(repo_root),
                            line=idx,
                            kind=kind,
                            masked=mask_secret(value, repo_root),
                        )
                    )
    except OSError as exc:  # pragma: no cover - Ø®Ø·Ø§Ù‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù†Ø§Ø¯Ø±
        raise ScanError(f"Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {path} Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯: {exc}") from exc
    return findings


def scan_repository(repo_root: Path, files: Optional[Sequence[Path]] = None) -> List[Finding]:
    repo_root = repo_root.resolve()
    candidates = files if files is not None else list(iter_candidate_files(repo_root))
    findings: List[Finding] = []
    for file_path in candidates:
        absolute = file_path if file_path.is_absolute() else repo_root / file_path
        findings.extend(scan_file(absolute, repo_root))
    findings.sort(key=lambda item: (str(item.file), item.line, item.kind, item.masked))
    return findings


def ensure_reports_dir(repo_root: Path) -> Path:
    reports_dir = repo_root / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)
    return reports_dir


def atomic_write_report(repo_root: Path, findings: Sequence[Finding]) -> Path:
    reports_dir = ensure_reports_dir(repo_root)
    target = reports_dir / "pii-scan.json"
    payload = {
        "findings": [
            {
                "file": str(item.file).replace(os.sep, "/"),
                "kind": item.kind,
                "line": item.line,
                "masked": item.masked,
            }
            for item in findings
        ]
    }
    serialized = json.dumps(payload, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    tmp_path = target.with_suffix(".json.part")
    with open(tmp_path, "w", encoding="utf-8") as handle:
        handle.write(serialized)
        handle.flush()
        os.fsync(handle.fileno())
    os.replace(tmp_path, target)
    return target


def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Ø§Ø³Ú©Ù† Ù…Ø®Ø²Ù† Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³")
    parser.add_argument(
        "paths",
        nargs="*",
        help="Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†Ø› Ø¯Ø± ØµÙˆØ±Øª Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯Ù† Ú©Ù„ Ù…Ø®Ø²Ù† Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.",
    )
    parser.add_argument(
        "--repo-root",
        type=Path,
        default=None,
        help="Ø±ÛŒØ´Ù‡Ù” Ù…Ø®Ø²Ù† (Ø¨Ù‡ Ø·ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯).",
    )
    return parser.parse_args(argv)


def run(argv: Optional[Sequence[str]] = None) -> int:
    try:
        args = parse_args(argv)
        repo_root = compute_repo_root(args.repo_root)
        if args.paths:
            files = [Path(arg) for arg in args.paths]
        else:
            files = None
        findings = scan_repository(repo_root, files)
        atomic_write_report(repo_root, findings)
    except ScanError as exc:
        print(f"Ø®Ø·Ø§ÛŒ Ø§Ø³Ú©Ù† Ø¯Ø§Ø¯Ù‡Ù” Ø­Ø³Ø§Ø³: {exc}")
        return 2
    if findings:
        print("ðŸš« Ø¯Ø§Ø¯Ù‡Ù” Ø­Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ø› Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± reports/pii-scan.json Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.")
        return 1
    print("âœ… Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡Ù” Ø­Ø³Ø§Ø³ ÛŒØ§ÙØª Ù†Ø´Ø¯Ø› Ú¯Ø²Ø§Ø±Ø´ Ø®Ø§Ù„ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    return 0


def main() -> int:  # pragma: no cover - Ù†Ù‚Ø·Ù‡Ù” ÙˆØ±ÙˆØ¯ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª
    return run()


if __name__ == "__main__":  # pragma: no cover - Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
    raise SystemExit(main())
